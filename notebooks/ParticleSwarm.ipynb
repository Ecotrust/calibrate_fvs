{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "import subprocess\n",
    "#from matplotlib import pyplot as plt\n",
    "#from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import sqlite3\n",
    "import glob\n",
    "import openpyxl\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib import pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set_style('darkgrid')\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load pso.py\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from diversipy import hycusampling\n",
    "\n",
    "def _obj_wrapper(func, args, kwargs, x):\n",
    "    return func(x, *args, **kwargs)\n",
    "\n",
    "def _is_feasible_wrapper(func, x):\n",
    "    return np.all(func(x)>=0)\n",
    "\n",
    "def _cons_none_wrapper(x):\n",
    "    return np.array([0])\n",
    "\n",
    "def _cons_ieqcons_wrapper(ieqcons, args, kwargs, x):\n",
    "    return np.array([y(x, *args, **kwargs) for y in ieqcons])\n",
    "\n",
    "def _cons_f_ieqcons_wrapper(f_ieqcons, args, kwargs, x):\n",
    "    return np.array(f_ieqcons(x, *args, **kwargs))\n",
    "    \n",
    "def pso(func, lb, ub, ieqcons=[], f_ieqcons=None, args=(), kwargs={}, \n",
    "        swarmsize=100, omega=0.5, phip=0.5, phig=0.5, maxiter=100, \n",
    "        minstep=1e-8, minfunc=1e-8, debug=False, processes=1,\n",
    "        particle_output=False):\n",
    "    \"\"\"\n",
    "    Perform a particle swarm optimization (PSO)\n",
    "   \n",
    "    Parameters\n",
    "    ==========\n",
    "    func : function\n",
    "        The function to be minimized\n",
    "    lb : array\n",
    "        The lower bounds of the design variable(s)\n",
    "    ub : array\n",
    "        The upper bounds of the design variable(s)\n",
    "   \n",
    "    Optional\n",
    "    ========\n",
    "    ieqcons : list\n",
    "        A list of functions of length n such that ieqcons[j](x,*args) >= 0.0 in \n",
    "        a successfully optimized problem (Default: [])\n",
    "    f_ieqcons : function\n",
    "        Returns a 1-D array in which each element must be greater or equal \n",
    "        to 0.0 in a successfully optimized problem. If f_ieqcons is specified, \n",
    "        ieqcons is ignored (Default: None)\n",
    "    args : tuple\n",
    "        Additional arguments passed to objective and constraint functions\n",
    "        (Default: empty tuple)\n",
    "    kwargs : dict\n",
    "        Additional keyword arguments passed to objective and constraint \n",
    "        functions (Default: empty dict)\n",
    "    swarmsize : int\n",
    "        The number of particles in the swarm (Default: 100)\n",
    "    omega : scalar\n",
    "        Particle velocity scaling factor (Default: 0.5)\n",
    "    phip : scalar\n",
    "        Scaling factor to search away from the particle's best known position\n",
    "        (Default: 0.5)\n",
    "    phig : scalar\n",
    "        Scaling factor to search away from the swarm's best known position\n",
    "        (Default: 0.5)\n",
    "    maxiter : int\n",
    "        The maximum number of iterations for the swarm to search (Default: 100)\n",
    "    minstep : scalar\n",
    "        The minimum stepsize of swarm's best position before the search\n",
    "        terminates (Default: 1e-8)\n",
    "    minfunc : scalar\n",
    "        The minimum change of swarm's best objective value before the search\n",
    "        terminates (Default: 1e-8)\n",
    "    debug : boolean\n",
    "        If True, progress statements will be displayed every iteration\n",
    "        (Default: False)\n",
    "    processes : int\n",
    "        The number of processes to use to evaluate objective function and \n",
    "        constraints (default: 1)\n",
    "    particle_output : boolean\n",
    "        Whether to include the best per-particle position and the objective\n",
    "        values at those.\n",
    "   \n",
    "    Returns\n",
    "    =======\n",
    "    g : array\n",
    "        The swarm's best known position (optimal design)\n",
    "    f : scalar\n",
    "        The objective value at ``g``\n",
    "    p : array\n",
    "        The best known position per particle\n",
    "    pf: arrray\n",
    "        The objective values at each position in p\n",
    "   \n",
    "    \"\"\"\n",
    "   \n",
    "    assert len(lb)==len(ub), 'Lower- and upper-bounds must be the same length'\n",
    "    assert hasattr(func, '__call__'), 'Invalid function handle'\n",
    "    lb = np.array(lb)\n",
    "    ub = np.array(ub)\n",
    "    assert np.all(ub>lb), 'All upper-bound values must be greater than lower-bound values'\n",
    "   \n",
    "    vhigh = np.abs(ub - lb)\n",
    "    vlow = -vhigh\n",
    "\n",
    "    # Initialize objective function\n",
    "    obj = partial(_obj_wrapper, func, args, kwargs)\n",
    "    \n",
    "    # Check for constraint function(s) #########################################\n",
    "    if f_ieqcons is None:\n",
    "        if not len(ieqcons):\n",
    "            if debug:\n",
    "                print('No constraints given.')\n",
    "            cons = _cons_none_wrapper\n",
    "        else:\n",
    "            if debug:\n",
    "                print('Converting ieqcons to a single constraint function')\n",
    "            cons = partial(_cons_ieqcons_wrapper, ieqcons, args, kwargs)\n",
    "    else:\n",
    "        if debug:\n",
    "            print('Single constraint function given in f_ieqcons')\n",
    "        cons = partial(_cons_f_ieqcons_wrapper, f_ieqcons, args, kwargs)\n",
    "    is_feasible = partial(_is_feasible_wrapper, cons)\n",
    "\n",
    "    # Initialize the multiprocessing module if necessary\n",
    "    if processes > 1:\n",
    "        import multiprocessing\n",
    "        mp_pool = multiprocessing.Pool(processes)\n",
    "        \n",
    "    # Initialize the particle swarm ############################################\n",
    "    S = swarmsize\n",
    "    D = len(lb)  # the number of dimensions each particle has\n",
    "    # x = np.random.rand(S, D)  # particle positions\n",
    "    x = hycusampling.random_k_means(S, D)  # assigns points to voronoi centroids of the D-dimensional unit hypercube\n",
    "    v = np.zeros_like(x)  # particle velocities\n",
    "    p = np.zeros_like(x)  # best particle positions\n",
    "    fx = np.zeros(S)  # current particle function values\n",
    "    fs = np.zeros(S, dtype=bool)  # feasibility of each particle\n",
    "    fp = np.ones(S)*np.inf  # best particle function values\n",
    "    g = []  # best swarm position\n",
    "    fg = np.inf  # best swarm position starting value\n",
    "    \n",
    "    # Initialize the particle's position\n",
    "    x = lb + x*(ub - lb)\n",
    "\n",
    "    # Calculate objective and constraints for each particle\n",
    "    if processes > 1:\n",
    "        fx = np.array(mp_pool.map(obj, x))\n",
    "        fs = np.array(mp_pool.map(is_feasible, x))\n",
    "    else:\n",
    "        for i in range(S):\n",
    "            fx[i] = obj(x[i, :])\n",
    "            fs[i] = is_feasible(x[i, :])\n",
    "       \n",
    "    # Store particle's best position (if constraints are satisfied)\n",
    "    i_update = np.logical_and((fx < fp), fs)\n",
    "    p[i_update, :] = x[i_update, :].copy()\n",
    "    fp[i_update] = fx[i_update]\n",
    "\n",
    "    # Update swarm's best position\n",
    "    i_min = np.argmin(fp)\n",
    "    if fp[i_min] < fg:\n",
    "        fg = fp[i_min]\n",
    "        g = p[i_min, :].copy()\n",
    "    else:\n",
    "        # At the start, there may not be any feasible starting point, so just\n",
    "        # give it a temporary \"best\" point since it's likely to change\n",
    "        g = x[0, :].copy()\n",
    "       \n",
    "    # Initialize the particle's velocity\n",
    "    v = vlow + np.random.rand(S, D)*(vhigh - vlow)\n",
    "       \n",
    "    # Iterate until termination criterion met ##################################\n",
    "    it = 1\n",
    "    while it <= maxiter:\n",
    "        rp = np.random.uniform(size=(S, D))\n",
    "        rg = np.random.uniform(size=(S, D))\n",
    "\n",
    "        # Update the particles velocities\n",
    "        v = omega*v + phip*rp*(p - x) + phig*rg*(g - x)\n",
    "        # Update the particles' positions\n",
    "        x = x + v\n",
    "        # Correct for bound violations\n",
    "        maskl = x < lb\n",
    "        masku = x > ub\n",
    "        x = x*(~np.logical_or(maskl, masku)) + lb*maskl + ub*masku\n",
    "\n",
    "        # Update objectives and constraints\n",
    "        if processes > 1:\n",
    "            fx = np.array(mp_pool.map(obj, x))\n",
    "            fs = np.array(mp_pool.map(is_feasible, x))\n",
    "        else:\n",
    "            for i in range(S):\n",
    "                fx[i] = obj(x[i, :])\n",
    "                fs[i] = is_feasible(x[i, :])\n",
    "\n",
    "        # Store particle's best position (if constraints are satisfied)\n",
    "        i_update = np.logical_and((fx < fp), fs)\n",
    "        p[i_update, :] = x[i_update, :].copy()\n",
    "        fp[i_update] = fx[i_update]\n",
    "\n",
    "        # Compare swarm's best position with global best position\n",
    "        i_min = np.argmin(fp)\n",
    "        if fp[i_min] < fg:\n",
    "            if debug:\n",
    "                print('New best for swarm at iteration {:}: {:} {:}'\\\n",
    "                    .format(it, p[i_min, :], fp[i_min]))\n",
    "\n",
    "            p_min = p[i_min, :].copy()\n",
    "            stepsize = np.sqrt(np.sum((g - p_min)**2))\n",
    "\n",
    "            if np.abs(fg - fp[i_min]) <= minfunc:\n",
    "                print('Stopping search: Swarm best objective change less than {:}'\\\n",
    "                    .format(minfunc))\n",
    "                if particle_output:\n",
    "                    return p_min, fp[i_min], p, fp\n",
    "                else:\n",
    "                    return p_min, fp[i_min]\n",
    "            elif stepsize <= minstep:\n",
    "                print('Stopping search: Swarm best position change less than {:}'\\\n",
    "                    .format(minstep))\n",
    "                if particle_output:\n",
    "                    return p_min, fp[i_min], p, fp\n",
    "                else:\n",
    "                    return p_min, fp[i_min]\n",
    "            else:\n",
    "                g = p_min.copy()\n",
    "                fg = fp[i_min]\n",
    "\n",
    "        if debug:\n",
    "            print('Best after iteration {:}: {:} {:}'.format(it, g, fg))\n",
    "        it += 1\n",
    "\n",
    "    print('Stopping search: maximum iterations reached --> {:}'.format(maxiter))\n",
    "    \n",
    "    if processes > 1:\n",
    "        mp_pool.close()\n",
    "    \n",
    "    if not is_feasible(g):\n",
    "        print(\"However, the optimization couldn't find a feasible design. Sorry\")\n",
    "    if particle_output:\n",
    "        return g, fg, p, fp\n",
    "    else:\n",
    "        return g, fg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_param_dict(params, stand_id):\n",
    "    ''' Single species\n",
    "        FIXDG (diameter growth multiplier by species and diameter class)\n",
    "        MORTMULT (background mortality rate multiplier by species and diameter class)\n",
    "        SDIMAX (density-driven mortality parameter set for each species)\n",
    "    '''\n",
    "    param_dict = {}\n",
    "    #stand input\n",
    "    param_dict['stand_id'] = stand_id\n",
    "    \n",
    "    #input and output databases\n",
    "    param_dict['FVSIn'] = '../data/FVSIn.db'\n",
    "    param_dict['FVSOut'] = '../keyfiles/{}.db'.format(stand_id)\n",
    "    \n",
    "    #growth factors\n",
    "    #size classes: 3-5, 5-10, 10-15, 15-20, >20\n",
    "    param_dict['FIXDGm_sp'] = int(params[0])\n",
    "    param_dict['FIXDGm_0'] = round(params[1],8)\n",
    "    param_dict['FIXDGm_1'] = round(params[2],8)\n",
    "    param_dict['FIXDGm_2'] = round(params[3],8)\n",
    "    param_dict['FIXDGm_3'] = round(params[4],8)\n",
    "    param_dict['FIXDGm_4'] = round(params[5],8)\n",
    "    #background mortality factors\n",
    "    param_dict['MORTm_sp'] = int(params[0])\n",
    "    param_dict['MORTm_0'] = round(params[6],8)\n",
    "    param_dict['MORTm_1'] = round(params[7],8)\n",
    "    param_dict['MORTm_2'] = round(params[8],8)\n",
    "    param_dict['MORTm_3'] = round(params[9],8)\n",
    "    param_dict['MORTm_4'] = round(params[10],8)\n",
    "\n",
    "    #density driven mortality factors\n",
    "    param_dict['SDI_MAX'] = int(params[11])\n",
    "    param_dict['SDI_LB'] = 55\n",
    "    param_dict['SDI_UB'] = 85\n",
    "        \n",
    "    return param_dict\n",
    "\n",
    "def make_keyfile(template, param_dict):\n",
    "    filename = '../keyfiles/{}.key'.format(param_dict['stand_id'])\n",
    "    keyfile_path = os.path.abspath(filename)\n",
    "    with open(keyfile_path,'w') as keyfile:\n",
    "        keyfile.write(template.render(**param_dict))\n",
    "\n",
    "    return keyfile_path\n",
    "\n",
    "\n",
    "def get_run_data(stand_id):\n",
    "    CONN_STR = sqlite3.connect('../keyfiles/{}.db'.format(stand_id))\n",
    "    run_data = pd.read_sql_query(\"SELECT * from fvs_summary\", CONN_STR)\n",
    "    #run_data = pd.read_sql_query(\"SELECT * from fvs_summary\", CONN_STR).set_index('standid')\n",
    "    #run_data = pd.read_sql_query(\"SELECT * from fvs_compute\", CONN_STR).set_index('standid')\n",
    "    \n",
    "    return run_data\n",
    "\n",
    "\n",
    "def get_groundtruth(stand_id):\n",
    "    STAND_DATA = '../data/groundtruth.xlsx'\n",
    "    df = pd.read_excel(STAND_DATA).set_index('stand_id')\n",
    "\n",
    "    return df.loc[stand_id]\n",
    "\n",
    "def get_residuals(stand_id):\n",
    "\n",
    "    METRICS = ['Acc','Mort']\n",
    "    #ACC = ['comp_acc']\n",
    "    #MORT = ['comp_mort']\n",
    "    pred = get_run_data(stand_id)[METRICS].head(1)\n",
    "    #acc_pre = get_run_data(stand_id)[ACC].first()\n",
    "    #acc_post = get_run_data(stand_id)[ACC].last()\n",
    "    #pred_acc = acc_post - acc_pre\n",
    "    #pred_mort = get_run_data(stand_id)[MORT].first()\n",
    "    #pred = pred_acc.merge(pred_mort, on='stand_id')\n",
    "    obs = get_groundtruth(stand_id)[METRICS]\n",
    "\n",
    "    residuals = pred - obs\n",
    "    \n",
    "    return residuals\n",
    "\n",
    "def get_keyfile_template(path_to_template):\n",
    "    with open(path_to_template, 'r') as base_keyfile:\n",
    "        template = Template(base_keyfile.read())\n",
    "    return template\n",
    "\n",
    "\n",
    "def run_fvs(params, stand_id):\n",
    "    param_dict = make_param_dict(params, stand_id)\n",
    "    KEYFILE_TEMPLATE = '../models/Base_Rx.key'\n",
    "    template = get_keyfile_template(KEYFILE_TEMPLATE)\n",
    "    keyfile = make_keyfile(template, param_dict)\n",
    "\n",
    "    proc = subprocess.call(['/usr/local/bin/FVSnc',\n",
    "                           '--keywordfile={}'.format(keyfile)],\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)\n",
    "\n",
    "    # cleanup output files\n",
    "    #os.remove('./keyfiles/{}.trl'.format(stand_id))\n",
    "    os.remove('../keyfiles/{}.out'.format(stand_id))\n",
    "    os.remove('../keyfiles/{}.key'.format(stand_id))\n",
    "\n",
    "    return proc\n",
    "\n",
    "\n",
    "def run_score_batch(params, all_stands, sample_size=32, num_cores=16, target='both'):\n",
    "    \"\"\"\n",
    "    Objective function to be optimized by PSO.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "      parameters being tested in this step of the PSO\n",
    "    stand_ids : array\n",
    "      stands that will be simulated in this step of the PSO\n",
    "    num_cores : int\n",
    "      number of cores that will be used for parallel processing\n",
    "    target : str\n",
    "      one of 'growth', 'mortality', or 'both'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj_fun : scalar\n",
    "      score of objective function on this batch of simulations\n",
    "    \"\"\"\n",
    "    stand_ids = np.random.choice(all_stands, sample_size)\n",
    "    map_to_run = partial(run_fvs, params)\n",
    "    with multiprocessing.Pool(num_cores) as p:\n",
    "        procs = p.map(map_to_run, stand_ids)\n",
    "        resids = p.map(get_residuals, stand_ids)\n",
    "    \n",
    "    resid = pd.concat(resids, axis=0, ignore_index=True)\n",
    "\n",
    "    # sse = ((residuals)**2)\n",
    "    # mae = residuals.abs()\n",
    "    # bias = residuals\n",
    "\n",
    "    growth_sse = (resid['Acc']**2).sum()\n",
    "    growth_mae = resid['Acc'].abs().mean()\n",
    "    growth_bias = resid['Acc'].mean()\n",
    "        \n",
    "    mort_sse = (resid['Mort']**2).sum()\n",
    "    mort_mae = resid['Mort'].abs().mean()\n",
    "    mort_bias = resid['Mort'].mean()\n",
    "    \n",
    "    if target == 'growth':\n",
    "        obj_fun = growth_sse\n",
    "    elif target == 'mortality':\n",
    "        obj_fun = mort_sse\n",
    "    else: \n",
    "        obj_fun = growth_sse + mort_sse\n",
    "\n",
    "    return obj_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * from fvs_summary': no such table: fvs_summary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/sloreno/mambaforge/envs/geo/lib/python3.10/site-packages/pandas/io/sql.py\", line 2018, in execute\n    cur.execute(*args, **kwargs)\nsqlite3.OperationalError: no such table: fvs_summary\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/sloreno/mambaforge/envs/geo/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/sloreno/mambaforge/envs/geo/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_473/954490023.py\", line 66, in get_residuals\n    pred = get_run_data(stand_id)[METRICS].head(1)\n  File \"/tmp/ipykernel_473/954490023.py\", line 49, in get_run_data\n    run_data = pd.read_sql_query(\"SELECT * from fvs_summary\", CONN_STR)\n  File \"/home/sloreno/mambaforge/envs/geo/lib/python3.10/site-packages/pandas/io/sql.py\", line 397, in read_sql_query\n    return pandas_sql.read_query(\n  File \"/home/sloreno/mambaforge/envs/geo/lib/python3.10/site-packages/pandas/io/sql.py\", line 2078, in read_query\n    cursor = self.execute(*args)\n  File \"/home/sloreno/mambaforge/envs/geo/lib/python3.10/site-packages/pandas/io/sql.py\", line 2030, in execute\n    raise ex from exc\npandas.errors.DatabaseError: Execution failed on sql 'SELECT * from fvs_summary': no such table: fvs_summary\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m stand_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39m'\u001b[39m\u001b[39m../data/groundtruth.xlsx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m all_stands \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(stand_data\u001b[39m.\u001b[39mstand_id)\n\u001b[0;32m---> 32\u001b[0m best_params, obj_val \u001b[39m=\u001b[39m pso(run_score_batch, lb\u001b[39m=\u001b[39;49mLB, ub\u001b[39m=\u001b[39;49mUB,\n\u001b[1;32m     33\u001b[0m                            swarmsize\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, maxiter\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, processes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     34\u001b[0m                            kwargs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mnum_cores\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m32\u001b[39;49m, \n\u001b[1;32m     35\u001b[0m                                    \u001b[39m'\u001b[39;49m\u001b[39mall_stands\u001b[39;49m\u001b[39m'\u001b[39;49m: all_stands,\n\u001b[1;32m     36\u001b[0m                                    \u001b[39m'\u001b[39;49m\u001b[39msample_size\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m5\u001b[39;49m,\n\u001b[1;32m     37\u001b[0m                                    \u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mgrowth\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     38\u001b[0m                                    }\n\u001b[1;32m     39\u001b[0m                            )\n\u001b[1;32m     40\u001b[0m pso_results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(best_params, \n\u001b[1;32m     41\u001b[0m                            columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFIA_SPP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFIXDGm_0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFIXDGm_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFIXDGm_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFIXDGm_3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFIXDGm_4\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     42\u001b[0m                                     \u001b[39m'\u001b[39m\u001b[39mMORTm_0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMORTm_1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMORTm_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMORTm_3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMORTm_4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSDI_MAX\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     43\u001b[0m                            )\n\u001b[1;32m     44\u001b[0m \u001b[39mprint\u001b[39m(pso_results)\n",
      "Cell \u001b[0;32mIn[4], line 148\u001b[0m, in \u001b[0;36mpso\u001b[0;34m(func, lb, ub, ieqcons, f_ieqcons, args, kwargs, swarmsize, omega, phip, phig, maxiter, minstep, minfunc, debug, processes, particle_output)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(S):\n\u001b[0;32m--> 148\u001b[0m         fx[i] \u001b[39m=\u001b[39m obj(x[i, :])\n\u001b[1;32m    149\u001b[0m         fs[i] \u001b[39m=\u001b[39m is_feasible(x[i, :])\n\u001b[1;32m    151\u001b[0m \u001b[39m# Store particle's best position (if constraints are satisfied)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36m_obj_wrapper\u001b[0;34m(func, args, kwargs, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_obj_wrapper\u001b[39m(func, args, kwargs, x):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[17], line 127\u001b[0m, in \u001b[0;36mrun_score_batch\u001b[0;34m(params, all_stands, sample_size, num_cores, target)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mwith\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mPool(num_cores) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m    126\u001b[0m     procs \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mmap(map_to_run, stand_ids)\n\u001b[0;32m--> 127\u001b[0m     resids \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mmap(get_residuals, stand_ids)\n\u001b[1;32m    129\u001b[0m resid \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(resids, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    131\u001b[0m \u001b[39m# sse = ((residuals)**2)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m# mae = residuals.abs()\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m# bias = residuals\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/geo/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/mambaforge/envs/geo/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * from fvs_summary': no such table: fvs_summary"
     ]
    }
   ],
   "source": [
    "LB = [202,   # fia species code\n",
    "      0.5,   # 'FIXDGm_0'\n",
    "      0.5,   # 'FIXDGm_1'\n",
    "      0.5,   # 'FIXDGm_2'\n",
    "      0.5,   # 'FIXDGm_3'\n",
    "      0.5,   # 'FIXDGm_4'\n",
    "      0.5,   # 'MORTm_0'\n",
    "      0.5,   # 'MORTm_1'\n",
    "      0.5,   # 'MORTm_2'\n",
    "      0.5,   # 'MORTm_3'\n",
    "      0.5,   # 'MORTm_4'\n",
    "      300,   # 'SDI_MAX'\n",
    "]             \n",
    "\n",
    "UB = [203,   # fia species code\n",
    "      1.5,   # 'FIXDGm_0'\n",
    "      1.5,   # 'FIXDGm_1'\n",
    "      1.5,   # 'FIXDGm_2'\n",
    "      1.5,   # 'FIXDGm_3'\n",
    "      1.5,   # 'FIXDGm_4'\n",
    "      1.5,   # 'MORTm_0'\n",
    "      1.5,   # 'MORTm_1'\n",
    "      1.5,   # 'MORTm_2'\n",
    "      1.5,   # 'MORTm_3'\n",
    "      1.5,   # 'MORTm_4'\n",
    "      1000,   # 'SDI_MAX'\n",
    "]  \n",
    "\n",
    "stand_data = pd.read_excel('../data/groundtruth.xlsx')\n",
    "all_stands = np.unique(stand_data.stand_id)\n",
    "\n",
    "best_params, obj_val = pso(run_score_batch, lb=LB, ub=UB,\n",
    "                           swarmsize=50, maxiter=25, processes=1,\n",
    "                           kwargs={'num_cores': 32, \n",
    "                                   'all_stands': all_stands,\n",
    "                                   'sample_size': 5,\n",
    "                                   'target': 'growth'\n",
    "                                   }\n",
    "                           )\n",
    "pso_results = pd.DataFrame(best_params, \n",
    "                           columns=['FIA_SPP', 'FIXDGm_0', 'FIXDGm_1', 'FIXDGm_2', 'FIXDGm_3', 'FIXDGm_4',\n",
    "                                    'MORTm_0', 'MORTm_1', 'MORTm_2', 'MORTm_3', 'MORTm_4', 'SDI_MAX']\n",
    "                           )\n",
    "print(pso_results)\n",
    "\n",
    "# xs = []\n",
    "# fxs = []\n",
    "# for site in SITES:\n",
    "#     empty_database()\n",
    "#     x, f_x = pso(partial(run_fvs, site_index=site, run_type='global'),\n",
    "#                  LB, UB,  # bounds\n",
    "#                  swarmsize=64,\n",
    "#                  maxiter=25,\n",
    "# #                  debug=True,\n",
    "#                  processes=32,\n",
    "#                  minfunc=0) # don't stop early\n",
    "#     xs.append(x)\n",
    "#     fxs.append(f_x)\n",
    "#     pso_results.loc[site, 'sdi_max'] = np.round(x[0],0).astype(int)\n",
    "#     pso_results.loc[site, 'df_dbh'] = np.round(x[1],8)\n",
    "#     pso_results.loc[site, 'f_x'] = f_x\n",
    "# print(pso_results)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dee7d4f533b7cd783ce13c45275c8722fb3f472a0b0cde8dbb181c050c075569"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
