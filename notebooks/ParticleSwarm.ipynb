{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from jinja2 import Template\n",
    "import subprocess\n",
    "from matplotlib import pyplot as plt\n",
    "#from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import sqlite3\n",
    "import glob\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load pso.py\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from diversipy import hycusampling\n",
    "\n",
    "def _obj_wrapper(func, args, kwargs, x):\n",
    "    return func(x, *args, **kwargs)\n",
    "\n",
    "def _is_feasible_wrapper(func, x):\n",
    "    return np.all(func(x)>=0)\n",
    "\n",
    "def _cons_none_wrapper(x):\n",
    "    return np.array([0])\n",
    "\n",
    "def _cons_ieqcons_wrapper(ieqcons, args, kwargs, x):\n",
    "    return np.array([y(x, *args, **kwargs) for y in ieqcons])\n",
    "\n",
    "def _cons_f_ieqcons_wrapper(f_ieqcons, args, kwargs, x):\n",
    "    return np.array(f_ieqcons(x, *args, **kwargs))\n",
    "    \n",
    "def pso(func, lb, ub, ieqcons=[], f_ieqcons=None, args=(), kwargs={}, \n",
    "        swarmsize=100, omega=0.5, phip=0.5, phig=0.5, maxiter=100, \n",
    "        minstep=1e-8, minfunc=1e-8, debug=False, processes=1,\n",
    "        particle_output=False):\n",
    "    \"\"\"\n",
    "    Perform a particle swarm optimization (PSO)\n",
    "   \n",
    "    Parameters\n",
    "    ==========\n",
    "    func : function\n",
    "        The function to be minimized\n",
    "    lb : array\n",
    "        The lower bounds of the design variable(s)\n",
    "    ub : array\n",
    "        The upper bounds of the design variable(s)\n",
    "   \n",
    "    Optional\n",
    "    ========\n",
    "    ieqcons : list\n",
    "        A list of functions of length n such that ieqcons[j](x,*args) >= 0.0 in \n",
    "        a successfully optimized problem (Default: [])\n",
    "    f_ieqcons : function\n",
    "        Returns a 1-D array in which each element must be greater or equal \n",
    "        to 0.0 in a successfully optimized problem. If f_ieqcons is specified, \n",
    "        ieqcons is ignored (Default: None)\n",
    "    args : tuple\n",
    "        Additional arguments passed to objective and constraint functions\n",
    "        (Default: empty tuple)\n",
    "    kwargs : dict\n",
    "        Additional keyword arguments passed to objective and constraint \n",
    "        functions (Default: empty dict)\n",
    "    swarmsize : int\n",
    "        The number of particles in the swarm (Default: 100)\n",
    "    omega : scalar\n",
    "        Particle velocity scaling factor (Default: 0.5)\n",
    "    phip : scalar\n",
    "        Scaling factor to search away from the particle's best known position\n",
    "        (Default: 0.5)\n",
    "    phig : scalar\n",
    "        Scaling factor to search away from the swarm's best known position\n",
    "        (Default: 0.5)\n",
    "    maxiter : int\n",
    "        The maximum number of iterations for the swarm to search (Default: 100)\n",
    "    minstep : scalar\n",
    "        The minimum stepsize of swarm's best position before the search\n",
    "        terminates (Default: 1e-8)\n",
    "    minfunc : scalar\n",
    "        The minimum change of swarm's best objective value before the search\n",
    "        terminates (Default: 1e-8)\n",
    "    debug : boolean\n",
    "        If True, progress statements will be displayed every iteration\n",
    "        (Default: False)\n",
    "    processes : int\n",
    "        The number of processes to use to evaluate objective function and \n",
    "        constraints (default: 1)\n",
    "    particle_output : boolean\n",
    "        Whether to include the best per-particle position and the objective\n",
    "        values at those.\n",
    "   \n",
    "    Returns\n",
    "    =======\n",
    "    g : array\n",
    "        The swarm's best known position (optimal design)\n",
    "    f : scalar\n",
    "        The objective value at ``g``\n",
    "    p : array\n",
    "        The best known position per particle\n",
    "    pf: arrray\n",
    "        The objective values at each position in p\n",
    "   \n",
    "    \"\"\"\n",
    "   \n",
    "    assert len(lb)==len(ub), 'Lower- and upper-bounds must be the same length'\n",
    "    assert hasattr(func, '__call__'), 'Invalid function handle'\n",
    "    lb = np.array(lb)\n",
    "    ub = np.array(ub)\n",
    "    assert np.all(ub>lb), 'All upper-bound values must be greater than lower-bound values'\n",
    "   \n",
    "    vhigh = np.abs(ub - lb)\n",
    "    vlow = -vhigh\n",
    "\n",
    "    # Initialize objective function\n",
    "    obj = partial(_obj_wrapper, func, args, kwargs)\n",
    "    \n",
    "    # Check for constraint function(s) #########################################\n",
    "    if f_ieqcons is None:\n",
    "        if not len(ieqcons):\n",
    "            if debug:\n",
    "                print('No constraints given.')\n",
    "            cons = _cons_none_wrapper\n",
    "        else:\n",
    "            if debug:\n",
    "                print('Converting ieqcons to a single constraint function')\n",
    "            cons = partial(_cons_ieqcons_wrapper, ieqcons, args, kwargs)\n",
    "    else:\n",
    "        if debug:\n",
    "            print('Single constraint function given in f_ieqcons')\n",
    "        cons = partial(_cons_f_ieqcons_wrapper, f_ieqcons, args, kwargs)\n",
    "    is_feasible = partial(_is_feasible_wrapper, cons)\n",
    "\n",
    "    # Initialize the multiprocessing module if necessary\n",
    "    if processes > 1:\n",
    "        import multiprocessing\n",
    "        mp_pool = multiprocessing.Pool(processes)\n",
    "        \n",
    "    # Initialize the particle swarm ############################################\n",
    "    S = swarmsize\n",
    "    D = len(lb)  # the number of dimensions each particle has\n",
    "    # x = np.random.rand(S, D)  # particle positions\n",
    "    x = hycusampling.random_k_means(S, D)  # assigns points to voronoi centroids of the D-dimensional unit hypercube\n",
    "    v = np.zeros_like(x)  # particle velocities\n",
    "    p = np.zeros_like(x)  # best particle positions\n",
    "    fx = np.zeros(S)  # current particle function values\n",
    "    fs = np.zeros(S, dtype=bool)  # feasibility of each particle\n",
    "    fp = np.ones(S)*np.inf  # best particle function values\n",
    "    g = []  # best swarm position\n",
    "    fg = np.inf  # best swarm position starting value\n",
    "    \n",
    "    # Initialize the particle's position\n",
    "    x = lb + x*(ub - lb)\n",
    "\n",
    "    # Calculate objective and constraints for each particle\n",
    "    if processes > 1:\n",
    "        fx = np.array(mp_pool.map(obj, x))\n",
    "        fs = np.array(mp_pool.map(is_feasible, x))\n",
    "    else:\n",
    "        for i in range(S):\n",
    "            fx[i] = obj(x[i, :])\n",
    "            fs[i] = is_feasible(x[i, :])\n",
    "       \n",
    "    # Store particle's best position (if constraints are satisfied)\n",
    "    i_update = np.logical_and((fx < fp), fs)\n",
    "    p[i_update, :] = x[i_update, :].copy()\n",
    "    fp[i_update] = fx[i_update]\n",
    "\n",
    "    # Update swarm's best position\n",
    "    i_min = np.argmin(fp)\n",
    "    if fp[i_min] < fg:\n",
    "        fg = fp[i_min]\n",
    "        g = p[i_min, :].copy()\n",
    "    else:\n",
    "        # At the start, there may not be any feasible starting point, so just\n",
    "        # give it a temporary \"best\" point since it's likely to change\n",
    "        g = x[0, :].copy()\n",
    "       \n",
    "    # Initialize the particle's velocity\n",
    "    v = vlow + np.random.rand(S, D)*(vhigh - vlow)\n",
    "       \n",
    "    # Iterate until termination criterion met ##################################\n",
    "    it = 1\n",
    "    while it <= maxiter:\n",
    "        rp = np.random.uniform(size=(S, D))\n",
    "        rg = np.random.uniform(size=(S, D))\n",
    "\n",
    "        # Update the particles velocities\n",
    "        v = omega*v + phip*rp*(p - x) + phig*rg*(g - x)\n",
    "        # Update the particles' positions\n",
    "        x = x + v\n",
    "        # Correct for bound violations\n",
    "        maskl = x < lb\n",
    "        masku = x > ub\n",
    "        x = x*(~np.logical_or(maskl, masku)) + lb*maskl + ub*masku\n",
    "\n",
    "        # Update objectives and constraints\n",
    "        if processes > 1:\n",
    "            fx = np.array(mp_pool.map(obj, x))\n",
    "            fs = np.array(mp_pool.map(is_feasible, x))\n",
    "        else:\n",
    "            for i in range(S):\n",
    "                fx[i] = obj(x[i, :])\n",
    "                fs[i] = is_feasible(x[i, :])\n",
    "\n",
    "        # Store particle's best position (if constraints are satisfied)\n",
    "        i_update = np.logical_and((fx < fp), fs)\n",
    "        p[i_update, :] = x[i_update, :].copy()\n",
    "        fp[i_update] = fx[i_update]\n",
    "\n",
    "        # Compare swarm's best position with global best position\n",
    "        i_min = np.argmin(fp)\n",
    "        if fp[i_min] < fg:\n",
    "            if debug:\n",
    "                print('New best for swarm at iteration {:}: {:} {:}'\\\n",
    "                    .format(it, p[i_min, :], fp[i_min]))\n",
    "\n",
    "            p_min = p[i_min, :].copy()\n",
    "            stepsize = np.sqrt(np.sum((g - p_min)**2))\n",
    "\n",
    "            if np.abs(fg - fp[i_min]) <= minfunc:\n",
    "                print('Stopping search: Swarm best objective change less than {:}'\\\n",
    "                    .format(minfunc))\n",
    "                if particle_output:\n",
    "                    return p_min, fp[i_min], p, fp\n",
    "                else:\n",
    "                    return p_min, fp[i_min]\n",
    "            elif stepsize <= minstep:\n",
    "                print('Stopping search: Swarm best position change less than {:}'\\\n",
    "                    .format(minstep))\n",
    "                if particle_output:\n",
    "                    return p_min, fp[i_min], p, fp\n",
    "                else:\n",
    "                    return p_min, fp[i_min]\n",
    "            else:\n",
    "                g = p_min.copy()\n",
    "                fg = fp[i_min]\n",
    "\n",
    "        if debug:\n",
    "            print('Best after iteration {:}: {:} {:}'.format(it, g, fg))\n",
    "        it += 1\n",
    "\n",
    "    print('Stopping search: maximum iterations reached --> {:}'.format(maxiter))\n",
    "    \n",
    "    if processes > 1:\n",
    "        mp_pool.close()\n",
    "    \n",
    "    if not is_feasible(g):\n",
    "        print(\"However, the optimization couldn't find a feasible design. Sorry\")\n",
    "    if particle_output:\n",
    "        return g, fg, p, fp\n",
    "    else:\n",
    "        return g, fg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_param_dict(params, stand_id):\n",
    "    ''' Single species\n",
    "        FIXDG (diameter growth multiplier by species and diameter class)\n",
    "        MORTMULT (background mortality rate multiplier by species and diameter class)\n",
    "        SDIMAX (density-driven mortality parameter set for each species)\n",
    "    '''\n",
    "    param_dict = {}\n",
    "    #stand input\n",
    "    param_dict['stand_id'] = stand_id\n",
    "    \n",
    "    #growth factors\n",
    "    #size classes: 3-5, 5-10, 10-15, 15-20, >20\n",
    "    param_dict['FIXDGm_sp'] = int(params[0])\n",
    "    param_dict['FIXDGm_0'] = round(params[1],8)\n",
    "    param_dict['FIXDGm_1'] = round(params[2],8)\n",
    "    param_dict['FIXDGm_2'] = round(params[3],8)\n",
    "    param_dict['FIXDGm_3'] = round(params[4],8)\n",
    "    param_dict['FIXDGm_4'] = round(params[5],8)\n",
    "    #background mortality factors\n",
    "    param_dict['MORTm_sp'] = int(params[0])\n",
    "    param_dict['MORTm_0'] = round(params[6],8)\n",
    "    param_dict['MORTm_1'] = round(params[7],8)\n",
    "    param_dict['MORTm_2'] = round(params[8],8)\n",
    "    param_dict['MORTm_3'] = round(params[9],8)\n",
    "    param_dict['MORTm_4'] = round(params[10],8)\n",
    "\n",
    "    #density driven mortality factors\n",
    "    param_dict['SDI_MAX'] = int(params[11])\n",
    "    param_dict['SDI_LB'] = 55\n",
    "    param_dict['SDI_UB'] = 85\n",
    "        \n",
    "    return param_dict\n",
    "\n",
    "def make_keyfile(template, param_dict):\n",
    "    filename = './keyfiles/{}.key'.format(param_dict['stand_id'])\n",
    "    keyfile_path = os.path.abspath(filename)\n",
    "    with open(keyfile_path,'w') as keyfile:\n",
    "        keyfile.write(template.render(**param_dict))\n",
    "\n",
    "    return keyfile_path\n",
    "\n",
    "\n",
    "def get_run_data(stand_id):\n",
    "    CONN_STR = sqlite3.connect('./keyfiles/{}.db'.format(stand_id))\n",
    "    run_data = pd.read_sql_query(\"SELECT * from fvs_summary\", CONN_STR).set_index('standid')\n",
    "\n",
    "    return run_data\n",
    "\n",
    "\n",
    "def get_groundtruth(stand_id):\n",
    "    STAND_DATA = './FIA_conds_DF.csv'\n",
    "    df = pd.read_csv(STAND_DATA).set_index('stand_id')\n",
    "\n",
    "    return df.loc[stand_id]\n",
    "\n",
    "def get_residuals(stand_id):\n",
    "\n",
    "    METRICS = ['acc','mort']\n",
    "    pred = get_run_data(stand_id)[METRICS].first()\n",
    "    obs = get_groundtruth(stand_id)[METRICS].first()\n",
    "\n",
    "    residuals = pred - obs\n",
    "    # sse = ((residuals)**2)\n",
    "    # mae = residuals.abs()\n",
    "    # bias = residuals\n",
    "    \n",
    "    return residuals\n",
    "\n",
    "def get_keyfile_template(path_to_template):\n",
    "    with open(path_to_template, 'r') as base_keyfile:\n",
    "        template = Template(base_keyfile.read())\n",
    "    return template\n",
    "\n",
    "\n",
    "def run_fvs(params, stand_id):\n",
    "    param_dict = make_param_dict(params, stand_id)\n",
    "    KEYFILE_TEMPLATE = '/models/Base_Rx.key'\n",
    "    template = get_keyfile_template(KEYFILE_TEMPLATE)\n",
    "    keyfile = make_keyfile(template, param_dict)\n",
    "\n",
    "    proc = subprocess.call(['/storage/src/open-fvs/trunk/bin/FVSpn',\n",
    "                           '--keywordfile={}'.format(keyfile)],\n",
    "                          stderr=subprocess.PIPE,\n",
    "                          stdout=subprocess.PIPE)\n",
    "\n",
    "    # cleanup output files\n",
    "    os.remove('./keyfiles/{}.trl'.format(stand_id))\n",
    "    os.remove('./keyfiles/{}.out'.format(stand_id))\n",
    "    os.remove('./keyfiles/{}.key'.format(stand_id))\n",
    "\n",
    "    return proc\n",
    "\n",
    "\n",
    "def run_score_batch(params, all_stands, sample_size=32, num_cores=16, target='both'):\n",
    "    \"\"\"\n",
    "    Objective function to be optimized by PSO.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array\n",
    "      parameters being tested in this step of the PSO\n",
    "    stand_ids : array\n",
    "      stands that will be simulated in this step of the PSO\n",
    "    num_cores : int\n",
    "      number of cores that will be used for parallel processing\n",
    "    target : str\n",
    "      one of 'growth', 'mortality', or 'both'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obj_fun : scalar\n",
    "      score of objective function on this batch of simulations\n",
    "    \"\"\"\n",
    "    stand_ids = np.random.choice(all_stands, sample_size)\n",
    "    map_to_run = partial(run_fvs, params=params)\n",
    "    with multiprocessing.Pool(num_cores) as p:\n",
    "        procs = p.map(map_to_run, stand_ids)\n",
    "        resids = p.map(get_residuals, stand_ids)\n",
    "    \n",
    "    resid = pd.concat(resids, axis=0, ignore_index=True)\n",
    "\n",
    "    # sse = ((residuals)**2)\n",
    "    # mae = residuals.abs()\n",
    "    # bias = residuals\n",
    "\n",
    "    growth_sse = (resid['acc']**2).sum()\n",
    "    growth_mae = resid['acc'].abs().mean()\n",
    "    growth_bias = resid['acc'].mean()\n",
    "        \n",
    "    mort_sse = (resid['mort']**2).sum()\n",
    "    mort_mae = resid['mort'].abs().mean()\n",
    "    mort_bias = resid['mort'].mean()\n",
    "    \n",
    "    if target == 'growth':\n",
    "        obj_fun = growth_sse\n",
    "    elif target == 'mortality':\n",
    "        obj_fun = mort_sse\n",
    "    else: \n",
    "        obj_fun = growth_sse + mort_sse\n",
    "\n",
    "    return obj_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "    sdi_max    df_dbh      f_x\n",
      "145     446   0.95872  1.36933\n",
      "135     402   1.07936  1.63002\n",
      "125     399  0.973043  1.91889\n",
      "115     400  0.893233  1.91118\n",
      "105     414  0.788779  1.82107\n",
      "95      425  0.688981  1.64722\n",
      "85      404  0.671923  1.60773\n",
      "75      473  0.552016   1.5992\n",
      "65      404  0.524992  1.77058\n"
     ]
    }
   ],
   "source": [
    "LB = [202,   # fia species code\n",
    "      0.5,   # 'FIXDGm_0'\n",
    "      0.5,   # 'FIXDGm_1'\n",
    "      0.5,   # 'FIXDGm_2'\n",
    "      0.5,   # 'FIXDGm_3'\n",
    "      0.5,   # 'FIXDGm_4'\n",
    "      0.5,   # 'MORTm_0'\n",
    "      0.5,   # 'MORTm_1'\n",
    "      0.5,   # 'MORTm_2'\n",
    "      0.5,   # 'MORTm_3'\n",
    "      0.5,   # 'MORTm_4'\n",
    "      300,   # 'SDI_MAX'\n",
    "]             \n",
    "\n",
    "UB = [202,   # fia species code\n",
    "      1.5,   # 'FIXDGm_0'\n",
    "      1.5,   # 'FIXDGm_1'\n",
    "      1.5,   # 'FIXDGm_2'\n",
    "      1.5,   # 'FIXDGm_3'\n",
    "      1.5,   # 'FIXDGm_4'\n",
    "      1.5,   # 'MORTm_0'\n",
    "      1.5,   # 'MORTm_1'\n",
    "      1.5,   # 'MORTm_2'\n",
    "      1.5,   # 'MORTm_3'\n",
    "      1.5,   # 'MORTm_4'\n",
    "      1000,   # 'SDI_MAX'\n",
    "]  \n",
    "\n",
    "stand_data = pd.read_csv(MY_STANDS)\n",
    "all_stands = np.unique(stand_data.stand_id)\n",
    "\n",
    "best_params, obj_val = pso(run_score_batch, lb=LB, ub=UB,\n",
    "                           swarmsize=50, maxiter=25, processes=32,\n",
    "                           kwargs={'num_cores': 32, \n",
    "                                   'all_stands': all_stands\n",
    "                                   'sample_size': 50,\n",
    "                                   'target': 'growth'\n",
    "                                   }\n",
    "                           )\n",
    "pso_results = pd.DataFrame(best_params, \n",
    "                           columns=['FIA_SPP', 'FIXDGm_0', 'FIXDGm_1', 'FIXDGm_2', 'FIXDGm_3', 'FIXDGm_4',\n",
    "                                    'MORTm_0', 'MORTm_1', 'MORTm_2', 'MORTm_3', 'MORTm_4', 'SDI_MAX']\n",
    "                           )\n",
    "print(pso_results)\n",
    "\n",
    "# xs = []\n",
    "# fxs = []\n",
    "# for site in SITES:\n",
    "#     empty_database()\n",
    "#     x, f_x = pso(partial(run_fvs, site_index=site, run_type='global'),\n",
    "#                  LB, UB,  # bounds\n",
    "#                  swarmsize=64,\n",
    "#                  maxiter=25,\n",
    "# #                  debug=True,\n",
    "#                  processes=32,\n",
    "#                  minfunc=0) # don't stop early\n",
    "#     xs.append(x)\n",
    "#     fxs.append(f_x)\n",
    "#     pso_results.loc[site, 'sdi_max'] = np.round(x[0],0).astype(int)\n",
    "#     pso_results.loc[site, 'df_dbh'] = np.round(x[1],8)\n",
    "#     pso_results.loc[site, 'f_x'] = f_x\n",
    "# print(pso_results)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c446eef832ec964573dc49f36fd16bdbed40cbfbefbf557bc2dc78d9e7968689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
